{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cImkluvhDcOS"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrHe7IOYqR4W"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import gensim.downloader as api\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "CzncQ0V8NzeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.34.0 scikit-learn==1.3.1 gdown==4.7.1\n"
      ],
      "metadata": {
        "id": "7xLJbyacOWiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade huggingface_hub\n"
      ],
      "metadata": {
        "id": "PseobneKbZ6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Load ClinicalBERT from Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wN3G-0Vacvko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqkdP5taYZGj"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Qccn5dJtW7"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IH7_32rFJv58"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('triage.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize function"
      ],
      "metadata": {
        "id": "9hJ_FP2qkq-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "UiN7d3C0kuja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxEKBgvDmGUu"
      },
      "source": [
        "## Preprocess function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vector(complaint):\n",
        "    inputs = preprocess(complaint)\n",
        "    outputs = model(**inputs)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "    cls_embedding = cls_embedding.detach().numpy()\n",
        "    return cls_embedding\n"
      ],
      "metadata": {
        "id": "nHnzNFcSoNz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF_rsNyBKYPJ"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "Nq1UDrADnnOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmP5r0XP_Sls"
      },
      "outputs": [],
      "source": [
        "X = dataset.iloc[:, [0,1,10]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cls_embeddings = [get_vector(complaint) for complaint in X.iloc[:,2]]"
      ],
      "metadata": {
        "id": "sVVTD8lamTAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_embeddings = np.vstack(cls_embeddings)"
      ],
      "metadata": {
        "id": "g7ScRsWyXv7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxSU15rTobRY"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(cls_embeddings)\n",
        "\n",
        "pca = PCA()\n",
        "pca.fit(scaled_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PisYjGUwo-lc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1),\n",
        "         np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('Scree Plot')\n",
        "plt.axhline(y=0.95, color='r', linestyle='--')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnDyv2XQpRKD"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=70)  # e.g., 50\n",
        "reduced_vectors = pca.fit_transform(scaled_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnNzp_v1DJPE"
      },
      "outputs": [],
      "source": [
        "X = X.join(pd.DataFrame(reduced_vectors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSNvj-brqsgw"
      },
      "outputs": [],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWC2EWp2Lx5G"
      },
      "source": [
        "## Using the elbow method to find the optimal number of clusters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import plotly.express as px\n",
        "\n",
        "neighbors = 40\n",
        "# X_embedded is your data\n",
        "nbrs = NearestNeighbors(n_neighbors=neighbors ).fit(reduced_vectors)\n",
        "distances, indices = nbrs.kneighbors(reduced_vectors)\n",
        "distance_desc = sorted(distances[:,neighbors-1], reverse=True)\n",
        "px.line(x=list(range(1,len(distance_desc )+1)),y= distance_desc )"
      ],
      "metadata": {
        "id": "Mn66gkZmqzXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install kneed\n",
        "from kneed import KneeLocator\n",
        "kneedle = KneeLocator(range(1,len(distance_desc)+1),  #x values\n",
        "                      distance_desc, # y values\n",
        "                      S=0.1, #parameter suggested from paper\n",
        "                      curve=\"convex\", #parameter from figure\n",
        "                      direction=\"decreasing\",\n",
        "                      online=False,\n",
        "                      interp_method='polynomial',\n",
        "                      polynomial_degree=15) #parameter from figure"
      ],
      "metadata": {
        "id": "TtJPuZSZaYF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kneedle.plot_knee_normalized()"
      ],
      "metadata": {
        "id": "JvVVpp1tafNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(kneedle.norm_knee)"
      ],
      "metadata": {
        "id": "PgUN8x4csBjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgT0mANLL4Nz"
      },
      "source": [
        "## Training the DBSCAN model on the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjEfU6ZSMAPl"
      },
      "source": [
        "dbscan = DBSCAN(eps=kneedle.norm_knee*80, min_samples=4)\n",
        "y_dbscan= dbscan.fit_predict(reduced_vectors, y=None, sample_weight=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r9ju_deQDNx"
      },
      "source": [
        "## Visualising the clusters in 2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlKl5K2KP1C9"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Assuming X is a pandas DataFrame, convert it to a NumPy array\n",
        "#X_dense = X.values\n",
        "\n",
        "# Reduce dimensions (here using PCA for demonstration; consider t-SNE or MDS for better handling of categorical variables)\n",
        "pca = PCA(n_components=2)\n",
        "vectors_pca = pca.fit_transform(reduced_vectors) # Pass the dense array here"
      ],
      "metadata": {
        "id": "3DDSWTWJs5nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(vectors_pca[:, 0], vectors_pca[:, 1], c=y_dbscan, cmap='viridis', label='Cluster ID')\n",
        "plt.colorbar(ticks=range(25), label='Cluster ID')  # Adjust the range according to your number of clusters\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('Cluster Plot with K-Prototypes Clustering')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kSQBmbbiUYZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB6G8pmyUwSn"
      },
      "source": [
        "## Visualising the clusters in 3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vmo7x2vyUzoF"
      },
      "outputs": [],
      "source": [
        "# Apply PCA to reduce dimensions to three\n",
        "pca = PCA(n_components=3)\n",
        "vectors_pca = pca.fit_transform(reduced_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Create a 3D plot\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Scatter plot using the first three PCA components\n",
        "scatter = ax.scatter(vectors_pca[:, 0], vectors_pca[:, 1], vectors_pca[:, 2], c=y_dbscan, cmap='viridis', marker='o')\n",
        "\n",
        "# Create a color bar\n",
        "colorbar = fig.colorbar(scatter, ax=ax, ticks=range(13))  # Adjust range for your number of clusters\n",
        "colorbar.set_label('Cluster ID')\n",
        "\n",
        "ax.set_xlabel('Principal Component 1')\n",
        "ax.set_ylabel('Principal Component 2')\n",
        "ax.set_zlabel('Principal Component 3')\n",
        "ax.set_title('3D Cluster Plot with K-Prototypes Clustering')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wEsJtZ8OAHZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68vbcW_3KMbC"
      },
      "source": [
        "## Extracting what is in each cluster"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_data = X.join(pd.DataFrame(y_dbscan, columns=['Cluster']))"
      ],
      "metadata": {
        "id": "0Id7jKe02TVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_data"
      ],
      "metadata": {
        "id": "C40X9GHy_zXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_data.to_csv('BERT_MIMIC_whole_clustered_dbscan_eps*80_4.csv', index=False)"
      ],
      "metadata": {
        "id": "O5JKbM6-7jaN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPTiTjtyNe/H4Ldv1DHKbe5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}